\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}
%\usepackage{parskip}
\usepackage{biblatex}
\addbibresource{proposal.bib}
\usepackage[letterpaper, portrait, margin=1in]{geometry}

% Definitions of handy macros can go here
\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

% Short headings should be running head and authors last names
\ShortHeadings{Proposal: Predicting EMS Response Time}{Acharya}
\firstpageno{1}

\begin{document}

\title{90-904 Project Proposal: Predicting EMS Response Times}

\author{\name Prithvi Acharya \email PACHARYA/acharyap@cmu.edu \\
       \addr Engineering and Public Policy\\
       Carnegie Mellon University\\
       Pittsburgh, PA, United States \\
       }
       
\maketitle
\section{Proposal Details} \label{details}
\subsection{What is your proposed analysis? What are the likely outcomes?}
The aim of this project is to test multiple machine learning models to predict the Emergency Medical Service (EMS) Response Time (i.e., the time between when an emergency call was received, to when the first EMS personnel arrive on the site of the incident) in New York City, and compare the models' prediction capabilities. In addition to the primary outcome --- real-time predictions of Response Time, to provide more accurate information to callers and first responders --- these models can also serve as a planning tool for the City, since they will assess the importance of several geographic, temporal and and severity features, allowing officials to better understand hindrances to faster response times.

\subsection{Why is your proposed analysis important?}
During a medical emergency, it is critical that paramedics and first responders are able arrive at the scene, and provide care expediently, for medical interventions to be effective. In their data-driven 2008 study, Blackwell and Kaufman found that in an urban American setting, the mortality risk for patients where the response time exceeded five minutes, was over three times higher, than that when the response time was under five minutes \cite{blackwellrte}. Hence, a tool allowing administrators to identify pain-points and design policies that lower response time, will be lifesaving. Furthermore, if EMS service operators are able to assess the expected response time, when a call is received, they will be much better prepared to talk the caller through any necessary triage, and provide them with reliable information, making the situation slightly less stressful for all those involved.


\subsection{How will your analysis contribute to existing work? Provide references.}
For the last decade, researchers across the country (including at the Heinz School \cite{yue2012efficient}) have applied data-driven tools, to understand policies with the potential to lower EMS response time. However, most of these models are focused on tool such as Geographic Information Systems and real-time ambulance location information, as opposed to predictive models based solely on information collected during the first contact call \cite{peleg2004geographic}. Further several researchers, eg. Maxwell et al. have developed effective and complex machine learning algorithms to predict response time \cite{maxwell2009ambulance}. \par The marginal contributions of our analysis will be:
\begin{itemize}
    \item Using several algorithms, as opposed to developing a single algorithm, to compare and contrast their performance in the case of New York City.
    \item Testing the model on the rich and up-to-date NYC dataset.
    \item Focusing only on features which can be determined during the initial call to EMS (i.e. before first responders have arrived at the scene).
\end{itemize}

\subsection{Describe the data. Please also define Y outcome(s), U treatment, V covariates, W population as applicable.}

As part of their Open Data Project, the City of New York makes publicly available, large data-sets regarding public infrastructure and services. The \emph{EMS Incident Dispatch Data} set contains nearly five million records (between 2013 and 2016) of EMS calls, including such features as  the severity level of the incident as reported during the EMS call, as well as geographic and temporal features (such as the ZIP Code and neighborhood of the incident, the date and time, and Boolean variables for some features including whether or not special events were causing unexpected traffic and congestion).

The $Y$ (outcome) in this case, as discussed earlier, is the recorded response time, and the $V$ (covariates) are restricted to features that can be discerned during the initial call (as opposed to features recorded after first-responders have arrived on the scene). The $W$ (population) is undefined since no randomized control trial is taking place. However, since the data-set is large, we can posit that a model constructed from this data should be fairly representative of expected response times at every address in New York City. Given the unique size, density and design of New York City, it is unclear whether inferences from this study will translate to other studies. No specific "treatment" is discussed in this project, but upon development of the models, some causal links may be evident.

\subsection{What evaluation measures are appropriate for the analysis? Which measures will you use?}

Since our aim is to predict and optimize the response time is - therefore, the evaluation of models will be based on their ability to predict the response time. Since several models will be used, the specific model evaluation methods will vary from model to model, but will all hinge on the models' ability to predict this one parameter.

\subsection{What study design, pre-processing, and machine learning methods do you intend to use? Justify that the analysis is of appropriate size for a course project.}

The raw data requires pre-processing to remove any instances where an EMS response was not sent, etc. Further, demographic and census data (which we may use as regressors) are available in other publicly available data-sets, which will require to be carefully merged with our primary raw data. The study design is relatively simple, developing a slew of machine learning models (using the various regressor models available in packages such as SciKit and Tensorflow). Data from 2013 through 2015 will be used to train and tune (through cross-validation) the models, which will be tested on data for the last year. While the intention is to not build one complex model, and each of the models developed will be relatively simple, since we develop, test and benchmark half a dozen models, we will gain insights into each model's strengths and weaknesses in the context of this type of prediction -- an appropriately sized task for this course project. 

\subsection{What are possible limitations of the study?}
Since we only have information from the EMS call-center, we run the risk of these models suffering from omitted variable bias. A better predictor can likely be developed using geographic models of the locations of ambulances and hospitals etc. In connection to this, we must note that since this data has been highly anonymized, our models are, by definition, going to be underfit. Further, our model might reinforce biases inherent to the data collection (specifically, with regard to the \emph{severity} as stated by the caller, etc.). 

\newpage
\printbibliography
%\appendix
%\section*{Appendix A.}
%Some more details about those methods, so we can actually reproduce them.

\end{document}
